import{_ as t}from"./plugin-vue_export-helper-x3n3nnut.js";import{r as o,o as r,c as l,b as n,d as e,a,e as p}from"./app-zSMpBOKH.js";const i={},c=n("h1",{id:"funasr",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#funasr","aria-hidden":"true"},"#"),e(" FunASR")],-1),u={href:"https://blog.csdn.net/xiaommianyang/article/details/136040456",target:"_blank",rel:"noopener noreferrer"},d=n("br",null,null,-1),h={href:"https://developer.aliyun.com/ask/588391",target:"_blank",rel:"noopener noreferrer"},_={href:"https://github.com/modelscope/FunASR",target:"_blank",rel:"noopener noreferrer"},k=n("br",null,null,-1),m={href:"https://github.com/jianyangshi/funasr-android/tree/master",target:"_blank",rel:"noopener noreferrer"},f=n("br",null,null,-1),g={href:"https://www.modelscope.cn/models/iic/speech_UniASR_asr_2pass-minnan-16k-common-vocab3825",target:"_blank",rel:"noopener noreferrer"},b={href:"https://github.com/k2-fsa/sherpa-onnx",target:"_blank",rel:"noopener noreferrer"},v=n("br",null,null,-1),w={href:"https://github.com/k2-fsa/sherpa-onnx/releases/tag/asr-models",target:"_blank",rel:"noopener noreferrer"},x=n("br",null,null,-1),S={href:"https://github.com/k2-fsa/sherpa-onnx/releases/tag/tts-models",target:"_blank",rel:"noopener noreferrer"},y=n("br",null,null,-1),q={href:"https://github.com/k2-fsa/sherpa-onnx/releases/tag/speech-enhancement-models",target:"_blank",rel:"noopener noreferrer"},T=n("br",null,null,-1),V={href:"https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-recongition-models",target:"_blank",rel:"noopener noreferrer"},z=n("br",null,null,-1),R={href:"https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-segmentation-models",target:"_blank",rel:"noopener noreferrer"},A=n("br",null,null,-1),L={href:"https://huggingface.co/spaces/k2-fsa/text-to-speech",target:"_blank",rel:"noopener noreferrer"},j=n("br",null,null,-1),N={href:"https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition",target:"_blank",rel:"noopener noreferrer"},B=n("br",null,null,-1),E={href:"https://huggingface.co/spaces/k2-fsa/generate-subtitles-for-videos",target:"_blank",rel:"noopener noreferrer"},F=n("br",null,null,-1),I={href:"https://huggingface.co/spaces/k2-fsa/speaker-diarization",target:"_blank",rel:"noopener noreferrer"},M=n("br",null,null,-1),U={href:"https://modelscope.cn/profile/?tab=studio",target:"_blank",rel:"noopener noreferrer"},C={href:"https://huggingface.co/docs/transformers/model_doc/vits",target:"_blank",rel:"noopener noreferrer"},G=n("br",null,null,-1),H={href:"https://huggingface.co/facebook/mms-tts-nan",target:"_blank",rel:"noopener noreferrer"},W=n("br",null,null,-1),D={href:"https://huggingface.co/csukuangfj/vits-mms-nan",target:"_blank",rel:"noopener noreferrer"},J={href:"https://huggingface.co/TSukiLen/whisper-medium-chinese-tw-minnan",target:"_blank",rel:"noopener noreferrer"},K=n("br",null,null,-1),O={href:"https://huggingface.co/TSukiLen/whisper-small-chinese-tw-minnan",target:"_blank",rel:"noopener noreferrer"},P=p(`<p>生成的音频</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> VitsTokenizer<span class="token punctuation">,</span> VitsModel<span class="token punctuation">,</span> set_seed

tokenizer <span class="token operator">=</span> VitsTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;facebook/mms-tts-nan&quot;</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> VitsModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;facebook/mms-tts-nan&quot;</span><span class="token punctuation">)</span>

inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token operator">=</span><span class="token string">&quot;wo shi shui&quot;</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">&quot;pt&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># set_seed(555)</span>

<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
   outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>

waveform <span class="token operator">=</span> outputs<span class="token punctuation">.</span>waveform<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>保存</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torchaudio

<span class="token comment"># 保存为 WAV 文件（默认采样率 16kHz）</span>
torchaudio<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">&quot;output.wav&quot;</span><span class="token punctuation">,</span> waveform<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>sampling_rate<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,4);function Q(X,Y){const s=o("ExternalLinkIcon");return r(),l("div",null,[c,n("p",null,[n("a",u,[e("阿里巴巴语音识别funasr的android部署"),a(s)]),d,n("a",h,[e("modelscope-funasr本地部署到安卓"),a(s)]),n("a",_,[e("FunASR"),a(s)]),k,n("a",m,[e("funasr-android"),a(s)]),f,n("a",g,[e("UniASR语音识别-闽南语-通用-16k"),a(s)])]),n("p",null,[n("a",b,[e("sherpa-onnx"),a(s)]),v,n("a",w,[e("Releases/asr-models"),a(s)]),x,n("a",S,[e("Releases/tts-models"),a(s)]),y,n("a",q,[e("speech-enhancement-models"),a(s)]),T,n("a",V,[e("speaker-recongition-models"),a(s)]),z,n("a",R,[e("speaker-segmentation-models"),a(s)]),A,n("a",L,[e("Text-to-speech (TTS)"),a(s)]),j,n("a",N,[e("Automatic Speech Recognition"),a(s)]),B,n("a",E,[e("Generate subtitles for videos"),a(s)]),F,n("a",I,[e("Speaker diarization"),a(s)]),M,n("a",U,[e("ModelScope csukuangfj"),a(s)])]),n("p",null,[n("a",C,[e("VITS"),a(s)]),G,n("a",H,[e("facebook/mms-tts-nan"),a(s)]),W,n("a",D,[e("csukuangfj/vits-mms-nan"),a(s)])]),n("p",null,[n("a",J,[e("TSukiLen/whisper-medium-chinese-tw-minnan"),a(s)]),K,n("a",O,[e("TSukiLen/whisper-small-chinese-tw-minnan"),a(s)])]),P])}const nn=t(i,[["render",Q],["__file","funasr.html.vue"]]);export{nn as default};
